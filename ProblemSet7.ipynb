{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10566f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903a6a1f",
   "metadata": {},
   "source": [
    "# Problem Set 7\n",
    "\n",
    "### PHYS 441\n",
    "\n",
    "***\n",
    "\n",
    "Adam A Miller  \n",
    "16 November 2022  \n",
    "version 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77536135",
   "metadata": {},
   "source": [
    "Problem sets for Phys 441 are due 1 week after they are assigned at 11:59 pm. \n",
    "\n",
    "Every student is responsible for submitting their own *individual* solutions. Solutions must be either an executable jupyter notebook or Adobe PDF file submitted via Canvas. You must **show all your work**. Submissions that only include answers will have points deducted.\n",
    "\n",
    "If the problem set calls for an integral, please calculate the integral by hand (in general any problem with integrals will not require the use of mathematica or similar tools)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b99b503",
   "metadata": {},
   "source": [
    "If you wish to \"write mathematics\" in a Jupyter notebook, this can be done using LaTeX formatting.\n",
    "\n",
    "LaTeX is great at typesetting mathematics. Let $X_1, X_2, \\ldots, X_n$ be a sequence of independent and identically distributed random variables with $\\text{E}[X_i] = \\mu$ and $\\text{Var}[X_i] = \\sigma^2 < \\infty$, and let\n",
    "\n",
    "$$S_n = \\frac{X_1 + X_2 + \\cdots + X_n}{n}\n",
    "      = \\frac{1}{n}\\sum_{i}^{n} X_i\\$$\n",
    "      \n",
    "denote their mean. Then as $n$ approaches infinity, the random variables $\\sqrt{n}(S_n - \\mu)$ converge in distribution to a normal $\\mathcal{N}(0, \\sigma^2)$.\n",
    "\n",
    "You can find a [summary of all the LaTeX math symbols](https://www.overleaf.com/learn/latex/List_of_Greek_letters_and_math_symbols) from Overleaf. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0ebbc9",
   "metadata": {},
   "source": [
    "## New note\n",
    "\n",
    "**If you submit a jupyter notebook as a pdf MAKE SURE the pdf shows all the text/code within the cells. Lines of code that are very long do not automatically \"wrap\" when exporting to pdf**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228840a4",
   "metadata": {},
   "source": [
    "## Problem 1)\n",
    "\n",
    "In class we built a function to run the Metropolis Hastings algorithm in order to perform MCMC integration. We will expand on that example here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c990b1",
   "metadata": {},
   "source": [
    "**Problem 1a**\n",
    "\n",
    "Write a function `lnlikelihood` to calculate the log likelihood for observations $y = mx + b$, with uncertainties on the $y_i$. The inputs to this function should be the model parameters `theta`, as well as the observational data `y`, `y_unc`, and `x`.\n",
    "\n",
    "Write a function `lnprior` to calculate the log of the prior, for a **Gaussian** prior on $m$ and $b$. Use $P(m) = \\mathcal{N}(2,1)$ and $P(b) = \\mathcal{N}(10,5)$.\n",
    "\n",
    "Write a function `lnposterior` that calculates the log of the unnormalized posterior (i.e., you can ignore the evidence $P(D)$).\n",
    "\n",
    "*Hint* – these functions will be very similar to those from class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86040845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a71a2b7",
   "metadata": {},
   "source": [
    "**Problem 1b**\n",
    "\n",
    "Make a scatter plot of the following observations and show the uncertainties on y. \n",
    "\n",
    "y = [ 18.29736291, 34.27306694, 36.28221691, -12.50674116, 28.51698955,  6.76299299, 21.95796824,  5.10013127, 22.34652411, 26.24095257, -7.65134878,  6.85798303, 30.84023215, 26.86927236, 13.02012232, 36.19040675, 47.51320751, 27.11466315, 43.12450007, 31.19767253,  5.02105035, 14.74843143, 12.44910031, 14.46034553, 21.54930757]  \n",
    "y_unc = [10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.]  \n",
    "x = [18.46178619, 13.42550614, 19.38315408, 0.51402241, 20.13427388, 3.56157375, 8.44116633, 4.32288449, 10.59034577, 21.54963424, 0.09954113, 2.41771422, 11.84335386, 16.39501881, 13.68538744, 15.49224754, 17.42669444, 10.10883627, 15.5082423, 12.97417389, 10.29889807, 8.56701695, 13.70297965, 6.53515459, 15.36354875]\n",
    "\n",
    "*Hint* – you can execute the cell below to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe61629",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([ 18.29736291, 34.27306694, 36.28221691, -12.50674116, 28.51698955,  6.76299299, 21.95796824,  5.10013127, 22.34652411, 26.24095257, -7.65134878,  6.85798303, 30.84023215, 26.86927236, 13.02012232, 36.19040675, 47.51320751, 27.11466315, 43.12450007, 31.19767253,  5.02105035, 14.74843143, 12.44910031, 14.46034553, 21.54930757])\n",
    "y_unc = np.array([10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.])\n",
    "x = np.array([18.46178619, 13.42550614, 19.38315408, 0.51402241, 20.13427388, 3.56157375, 8.44116633, 4.32288449, 10.59034577, 21.54963424, 0.09954113, 2.41771422, 11.84335386, 16.39501881, 13.68538744, 15.49224754, 17.42669444, 10.10883627, 15.5082423, 12.97417389, 10.29889807, 8.56701695, 13.70297965, 6.53515459, 15.36354875])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a8ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1ee069",
   "metadata": {},
   "source": [
    "**Problem 1c**\n",
    "\n",
    "Write a function to run the MH algorithm and return the MCMC chain, the log of the posterior at every value within the chain, and the acceptance ratio for each step in the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df504452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00b272f",
   "metadata": {},
   "source": [
    "**Problem 1d**\n",
    "\n",
    "Using the above function, calculate an MCMC chain for 2000 steps. Use a covariance for the multivariate jump proposal `cov = [0.1, 2]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63df228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd940394",
   "metadata": {},
   "source": [
    "**Problem 1e**\n",
    "\n",
    "Plot the marginal distribution for the slope of the line $m$. Overplot the prior, as a solid line, on the same figure. \n",
    "\n",
    "What is the 68% credible region for $m$?\n",
    "\n",
    "*Hint* – the marginal distribution can be shown as a histogram.\n",
    "\n",
    "*Second hint* – did you account for burn-in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c8517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete\n",
    "# complete\n",
    "# complete\n",
    "\n",
    "print(f'The 68% credible region is:') # complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74a2fe2",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e284197",
   "metadata": {},
   "source": [
    "**Problem 1f**\n",
    "\n",
    "How does the maximum-likelihood estimate for $m$ compare?\n",
    "\n",
    "*Hint* – you can use any of the many different methods we have discussed to determine the MLE slope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ccd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd1624b",
   "metadata": {},
   "source": [
    "**Problem 1g**\n",
    "\n",
    "Calculate a new MCMC chain, but this time with $P(m) = \\mathcal{N}(2.5,0.1)$ and $P(b) = \\mathcal{N}(0,3)$.\n",
    "\n",
    "*Hint* – you only need to update `lnprior` everything else sould work just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b37a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f011f2",
   "metadata": {},
   "source": [
    "**Problem 1h**\n",
    "\n",
    "Using the above function, calculate an MCMC chain for 5000 steps. Use a covariance for the multivariate jump proposal `cov = [0.075, 1.5]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d157dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27f2581",
   "metadata": {},
   "source": [
    "**Problem 1i**\n",
    "\n",
    "Plot the marginal distribution for the slope of the line $m$. Overplot the prior, as a solid line, on the same figure. \n",
    "\n",
    "What is the 68% credible region for $m$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9a4b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete\n",
    "# complete\n",
    "# complete\n",
    "\n",
    "print(f'The 68% credible region is:') # complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e22ea",
   "metadata": {},
   "source": [
    "**Problem 1j**\n",
    "\n",
    "Select 7 random samples from your chain. Each of these constitutes a posterior predictive sample. Overplot the lines defined by these samples on top of the data. \n",
    "\n",
    "What can you say about the prior adopted in **1g**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d628ad",
   "metadata": {},
   "source": [
    "*write your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ae1c0f",
   "metadata": {},
   "source": [
    "## Problem 2)\n",
    "\n",
    "In this problem we will conduct a simple experiment and use the results to update priors.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a93a72",
   "metadata": {},
   "source": [
    "**Problem 2a** \n",
    "\n",
    "You are given a bag that has 4 bills of US currency in it. The bills are either $\\$1$ or $\\$100$, but you have no information about how many are $\\$1$ and how many are $\\$100$. \n",
    "\n",
    "Using the principle of indifference, write down a prior for the number of $\\$100$ bills in the bag. Plot the prior.\n",
    "\n",
    "*Hint* – the prior is discrete, but like all p.d.f.s must sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc007541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5817c525",
   "metadata": {},
   "source": [
    "**Problem 2b**\n",
    "\n",
    "You are allowed to select a single bill from the bag, and it is a $\\$100$. \n",
    "\n",
    "Calculate the likelihood for each possible configuration of bills given \"the data\" (i.e., that one drawn bill was $\\$100$). \n",
    "\n",
    "Plot the likelihood $p(\\textrm{draw a } \\$100 \\textrm{ bill} | N_{\\$100})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec187dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0954a83f",
   "metadata": {},
   "source": [
    "**Problem 2c**\n",
    "\n",
    "Using your likelihood and prior, calculate the posterior for the number of $\\$100$ bills in the bag. \n",
    "\n",
    "*Hint* – the posterior is a p.d.f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1819c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966718d2",
   "metadata": {},
   "source": [
    "**Problem 2d**\n",
    "\n",
    "The $\\$100$ bill is placed back in the bag. You select another bill from the bag, it is a $\\$1$ bill. \n",
    "\n",
    "Plot the likelihood given a $\\$1$ bill was drawn from the bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eafe9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f66777",
   "metadata": {},
   "source": [
    "**Problem 2e**\n",
    "\n",
    "Calculate the posterior for the number of $\\$100$ bills in the bag. Use the results from the first experiment as your prior for the second experiment.\n",
    "\n",
    "Do your results make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bf2296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e667ebd7",
   "metadata": {},
   "source": [
    "*write your answer here*\n",
    "\n",
    "In this case, yes, the results make sense. If we have drawn a bill of each type, then there is 0 probability that the bag is entirely made of only one type of bill. The most likely outcome in this case is also that have the bag is Washington and half is Benjamin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96943deb",
   "metadata": {},
   "source": [
    "## Problem 3)\n",
    "\n",
    "Unreliable experimentalists. \n",
    "\n",
    "You (foolishly!) decide to befriend an experimentalist. The experimentalist has collected some observations of a random variable that has a linear relationship to a dependent variable (i.e., $y = mx + b$). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d132c0",
   "metadata": {},
   "source": [
    "**Problem 3a**\n",
    "\n",
    "The experimentalist gives you the observations: \n",
    "\n",
    "y = [-323.06784362, 951.5329835, 1624.60411937, 523.71102977, 1686.81461432, 1145.33647822, 407.52259706, 89.49034911, 422.37688187, 1780.61985005, 2202.77330898, 593.47430676, 1207.13832901, 82.44438696, 852.46085987, 1725.32546389, 2118.72500295, 1714.81144005]  \n",
    "y_unc = [145.04890632, 156.95558291, 101.25609822, 70.28530931, 160.83777037, 121.67910032, 85.69670104, 59.59170488, 97.94085661, 64.82428022, 66.79395355, 83.56478711, 79.71422451, 97.82879082, 67.80030955, 117.7953663, 68.01463333, 97.25222409]\n",
    "x = [24.99003241, 9.39199623, 61.78810068, 6.12686943, 66.76437623, 76.27093556, 11.197759, 4.34864028, 41.85616486, 99.85155482, 97.88906765, 25.95412469, 56.43497299, 24.4771456, 32.52404943, 90.02733475, 95.55748004, 72.97647065]\n",
    "\n",
    "\n",
    "Make a scatter plot of the data. What are your first impressions of the observations?\n",
    "\n",
    "*Hint* – you can execute the cell below to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773645f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([-323.06784362, 951.5329835, 1624.60411937, 523.71102977, 1686.81461432, 1145.33647822, 407.52259706, 89.49034911, 422.37688187, 1780.61985005, 2202.77330898, 593.47430676, 1207.13832901, 82.44438696, 852.46085987, 1725.32546389, 2118.72500295, 1714.81144005])\n",
    "y_unc = np.array([145.04890632, 156.95558291, 101.25609822, 70.28530931, 160.83777037, 121.67910032, 85.69670104, 59.59170488, 97.94085661, 64.82428022, 66.79395355, 83.56478711, 79.71422451, 97.82879082, 67.80030955, 117.7953663, 68.01463333, 97.25222409])\n",
    "x = np.array([24.99003241, 9.39199623, 61.78810068, 6.12686943, 66.76437623, 76.27093556, 11.197759, 4.34864028, 41.85616486, 99.85155482, 97.88906765, 25.95412469, 56.43497299, 24.4771456, 32.52404943, 90.02733475, 95.55748004, 72.97647065])\n",
    "\n",
    "\n",
    "# complete\n",
    "# complete\n",
    "# complete\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ca08d3",
   "metadata": {},
   "source": [
    "*write your answer here*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb8543",
   "metadata": {},
   "source": [
    "**Problem 3b**\n",
    "\n",
    "Calculate the MLE for the slope and intercept of the line relating $y$ and $x$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd99a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9557aef",
   "metadata": {},
   "source": [
    "**Problem 3c**\n",
    "\n",
    "You suspect that your experimentalist friend has made a mistake. However, when you ask them if there may be any issues with the data the experimentalist becomes extremely defensive and decides to no longer talk to you. \n",
    "\n",
    "You are left to proceed with your analysis with no additional information about the experiment. \n",
    "\n",
    "A general way to adjust the model is to \"inflate\" the uncertainties by a constant scaling factor, $A$. In doing so, the normal Gaussian p.d.f. becomes: \n",
    "\n",
    "$$p(\\{y_i\\}|\\{x_i\\}, \\{\\sigma_{y_i}\\}, m, b, A) = \\frac{1}{\\sqrt{2\\pi A^2 \\sigma_{y_i}^2}} \\exp\\left(-\\frac{(y_i - mx_i - b)^2}{2A^2\\sigma_{y_i}^2}\\right)$$\n",
    "\n",
    "\n",
    "Write functions to calculate the likelihood, prior, and posterior for the given observations and model parameters $m, b,$ and $A$. \n",
    "\n",
    "*Hint* – think about the appropriate prior for A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d1677f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8516d62b",
   "metadata": {},
   "source": [
    "**Problem 3d**\n",
    "\n",
    "Run a MH MCMC for 25000 steps. Use `cov = [1,10,0.5]` for the sampler.\n",
    "\n",
    "*Hint* – you may need to refine your initial guess a few times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4d8829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6b35bb",
   "metadata": {},
   "source": [
    "**Problem 3e**\n",
    "\n",
    "Plot the chains for the slope and the intercept. Do you need to throw away some burn-in samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c9ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7ba0f6",
   "metadata": {},
   "source": [
    "*write your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e756f21",
   "metadata": {},
   "source": [
    "**Problem 3f**\n",
    "\n",
    "Plot the marginal distribution for the slope of the line. What is the 68% credible region on the slope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3628c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete\n",
    "\n",
    "print(f'The 68% credible region is:') # complete\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e26610",
   "metadata": {},
   "source": [
    "Using `np.polyfit` we can get the MLE confidence intervals on the slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf485b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, cov = np.polyfit(x, y, 1, w=1/y_unc, cov=True)\n",
    "\n",
    "print(f'The MLE slope is {p[0]:.2f} +/- {cov[0][0]**0.5:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c2a633",
   "metadata": {},
   "source": [
    "The true answer is that the slope is 23. In that sense we should prefer the Bayes estimate of the slope. \n",
    "\n",
    "But that's not the point! \n",
    "\n",
    "For real experiments we never know the \"true\" answer. But we may suspect that the uncertainties are incorrectly estimated. For both the frequentist case and the Bayesian case we can modify the model (and hence likelihood) to inflate the uncertainties by some factor $A$. But if we do this as a frequentist, then we are saying the uncertainties are *definitely* estimated incorrectly and by an amount $\\hat{A}$. As a Bayesian, we consider all possible values of $A$, and then integrate our estimate of the posterior over all values of $A$ to arrive at an estimate for $m$ (and it's credible region) *removing any dependence on A for that answer*! \n",
    "\n",
    "This is the power of Bayes, and why it is really useful for complex experiments/data systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
